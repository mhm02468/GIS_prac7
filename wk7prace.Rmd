---
title: "Week 7 Practical"
output: html_document
date: "2022-11-23"
---

```{r setup, include=FALSE}
#Libraries & data downloading
library(here)
library(janitor)
library(sf)
library(tidyverse)
library(RColorBrewer)
library(tmap)
library(sf)
library(spdep)

LondonWards <- st_read("/Users/martignoni/Documents/CASA/GIS/wk7/wk7prac/wk7data/London-wards-2018/London-wards-2018_ESRI/London_Ward.shp")


LondonWardsMerged <- st_read("/Users/martignoni/Documents/CASA/GIS/wk7/wk7prac/wk7data/London-wards-2018/London-wards-2018_ESRI/London_Ward_CityMerged.shp")%>%
  st_transform(.,27700)

WardData <- read_csv("https://data.london.gov.uk/download/ward-profiles-and-atlas/772d2d64-e8c6-46cb-86f9-e52b4c7851bc/ward-profiles-excel-version.csv", locale = locale(encoding = "latin1"), na = c("NA", "n/a")) %>% 
  clean_names()

LondonWardsMerged <- LondonWardsMerged %>% 
  left_join(WardData, by = c("GSS_CODE" = "new_code"))%>%
  dplyr::distinct(GSS_CODE, .keep_all = T)%>%
  dplyr::select(GSS_CODE, ward_name, average_gcse_capped_point_scores_2014)

BluePlaques <- st_read("https://s3.eu-west-2.amazonaws.com/openplaques/open-plaques-london-2018-04-08.geojson") %>% 
  st_transform(27700)

#Check the blue plaques were installed correctly

tmap_mode("plot")
tm_shape(LondonWardsMerged)+tm_polygons(col=NA, alpha=0.5)+
tm_shape(BluePlaques)+tm_dots(col="blue")

```

## Data Cleaning (subset the data)

```{r Data Cleaning}
#subset the data
BluePlaquesSub <- BluePlaques[LondonWardsMerged,]
```

## Data Manipulation

```{r Data Manipulation}
library(sf)

points_sf_joined <- LondonWardsMerged %>% 
  st_join(BluePlaquesSub) %>% 
  add_count(ward_name) %>%
  janitor::clean_names() %>% 
  #calculate the area
  mutate(area=st_area(.)) %>% 
  #calculate density per ward
  mutate(density=n/area) %>% 
  #select density and some other variables
  dplyr::select(density, ward_name, gss_code, n, average_gcse_capped_point_scores_2014)

points_sf_joined<- points_sf_joined %>%                    
  group_by(gss_code) %>%         
  summarise(density = first(density), wardname= first(ward_name), plaquecount= first(n))

tm_shape(points_sf_joined) + tm_polygons("density", style="jenks", palette="PuOr", midpoint=NA, popup.vars=c("wardname", "density"), title="Blue Plaque Density")
```

## Weight Matrix

1. First, you need to calculate centroids
2. To generate the matrix, there are few methods
    a. **binary/contiguity edges corners** = polygons with a shared edge or a corner will be included in computations for the target polygon)
    b. **distance** = done with "k" nearest neighbours where k is the closest observation
3. Matrix Styles:
  a. B is the basic binary coding (1/0)
  b. W is row standardised (sums over all links to n) =  1 is divided by the sum of the number of neighbours in each row.
  c. C is globally standardised (sums over all links to n) = dividing our 625 wards by the total number of neighbours
  d. U is equal to C divided by the number of neighbours (sums over all links to unity)
  e. S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).
  
*note*: this does not take into account if there is, for example, a river or other geographical boundary between two neighbours.


```{r Weight Matrix}
#calculate the centroids
coordsW <- points_sf_joined %>% 
  st_centroid() %>% 
  st_geometry()

#create a neighbours list
LWard_nb <- points_sf_joined %>% 
  poly2nb(., queen=T)

#plot them
plot(LWard_nb, st_geometry(coordsW), col="red")

#add a map underneath
plot(points_sf_joined$geometry, add=T)

#create a spatial weights matrix from these weights
Lward.lw <- LWard_nb %>% 
  nb2mat(.,style="B")

#sums the number of neighbours in the matrix
sum(Lward.lw)

#row standardisation
sum(Lward.lw[1,])

```

## Autocorrelation

1. Moran's I = tells use if we have clustered values (close to 1) or dispersed values (close to -1), here we'll use density OR 1 = clustered, 0 = no pattern, -1 = dispersed
  *local moran's I/Anselin Moran's I is doing this locally (i.e., per ward)*
2. Geary's C =  falls between 0 and 2, similar values or dissimilar values are clustering
  *1* means no spatial autocorrelation
  *less than 1* positive spatial autocorrelation or similar values clustering
  *greater than 1* mean negative spatial autocorreation or dissimilar values clustering
3. Getis Ord = the G value is > expected which means that high values are tending to cluster


```{r Autocorrelation}
#Moranâ€™s I requires a spatial weight list type object as opposed to matrix, so do the following:
Lward.lw <- LWard_nb %>%
  nb2listw(., style="C")

#Moran's I
I_LWard_Global_Density <- points_sf_joined %>%
  pull(density) %>%
  as.vector() %>%
  moran.test(., Lward.lw)

#Geary's C
C_LWard_Global_Density <- points_sf_joined %>% 
  pull(density) %>% 
  as.vector() %>% 
  geary.test(., Lward.lw)

#Getis Ord
G_LWard_Global_Density <- points_sf_joined %>%
  pull(density) %>%
  as.vector()%>%
  globalG.test(., Lward.lw)

#Use the local moran to generate I for each ward in the city
I_LWard_Local_count <- points_sf_joined %>%
  pull(plaquecount) %>%
  as.vector()%>%
  localmoran(., Lward.lw)%>%
  as_tibble()

I_LWard_Local_Density <- points_sf_joined %>%
  pull(density) %>%
  as.vector()%>%
  localmoran(., Lward.lw)%>%
  as_tibble()

#copy some of the columns (the I score (column 1) and the z-score standard deviation (column 4)) back into the LondonWards spatialPolygonsDataframe
points_sf_joined <- points_sf_joined %>%
  mutate(plaque_count_I = as.numeric(I_LWard_Local_count$Ii))%>%
  mutate(plaque_count_Iz =as.numeric(I_LWard_Local_count$Z.Ii))%>%
  mutate(density_I =as.numeric(I_LWard_Local_Density$Ii))%>%
  mutate(density_Iz =as.numeric(I_LWard_Local_Density$Z.Ii))

```

## Mapping

This will largely focus on mapping the local Moran's I output (for the wards).
1. *Breaks are set based on rules of normal dist*, the idea that data points >2.58 or <-2.58 standard deviations away from the mean are significant at the 99% level (<1% chance that autocorrelation not present); >1.96 - <2.58 or <-1.96 to >-2.58 standard deviations are significant at the 95% level (<5% change that autocorrelation not present). >1.65 = 90%. THIS COMES FROM THE Z SCORE DIST.
2. The z-score = standardised value relating to whether high values or low values are clustering together

```{r Mapping}
breaks1<-c(-1000,-2.58,-1.96,-1.65,1.65,1.96,2.58,1000)

MoranColours<- rev(brewer.pal(8, "RdGy"))

tm_shape(points_sf_joined) +
    tm_polygons("plaque_count_Iz", style="fixed", breaks=breaks1, palette=MoranColours, midpoint=NA, title="Local Moran's I, Blue Plaques in London")+ tm_layout(legend.outside = TRUE) 

#The Z-Score
Gi_LWard_Local_Density <- points_sf_joined %>%
  pull(density) %>%
  as.vector()%>%
  localG(., Lward.lw)

points_sf_joined <- points_sf_joined %>%
  mutate(density_G = as.numeric(Gi_LWard_Local_Density))

#Plot Local Getis Ord
GIColours<- rev(brewer.pal(8, "RdBu"))

tm_shape(points_sf_joined) + tm_polygons("density_G",  style="fixed", breaks=breaks1, palette=GIColours, midpoint=NA, title="Gi*, Blue Plaques in London")+ tm_layout(legend.outside = TRUE)
```
## Working with Avg GCSE scores

```{r GCSE}
I_LWard_Local_GCSE <- LondonWardsMerged %>%
  arrange(GSS_CODE) %>%
  pull(average_gcse_capped_point_scores_2014) %>%
  as.vector() %>%
  localmoran(., Lward.lw) %>%
  as_tibble()

points_sf_joined <- points_sf_joined %>%
  arrange(gss_code)%>%
  mutate(GCSE_LocIz = as.numeric(I_LWard_Local_GCSE$Z.Ii))

tm_shape(points_sf_joined) + tm_polygons("GCSE_LocIz", style="fixed", breaks=breaks1, palette=MoranColours, midpoint=NA, title="Local Moran's I, GCSE Scores")

```
